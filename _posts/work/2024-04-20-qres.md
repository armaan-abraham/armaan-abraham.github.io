---
layout: post
title: "RL-based generation of peptide sequences conditioned on fuzzy structural constraints"
date: 2024-09-30 12:00:00 -0500
excerpt: "Using Alphafold2 to train a reinforcement learning agent to generate peptide sequences conditioned on pairwise residue distance constraints."
github: "https://github.com/armaan-abraham/Qres"
importance: 1
---

[Github](https://github.com/armaan-abraham/Qres)

## Overview

[AlphaFold2](https://www.nature.com/articles/s41586-021-03819-2) allows us to
predict protein structure from sequence. Additionally, [inverse
models](https://www.biorxiv.org/content/10.1101/2022.04.10.487779v2) have also
been developed, which predict the sequences of naturally occurring proteins from
their structure. However, both of these models are limited in many protein
engineering contexts, where we have some particular structural feature that we
want to generate in an engineered protein.

A crucial problem here is that we __don't know exactly what protein structures
are possible__ (i.e. for which structures there exists some sequence), and our
structure-to-sequence models do not yet have the capability to find similar
structures, for which sequences exist, to a target structure. As [Po-Ssu Huang
says](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1010271),
"creating novel backbones for which there exist a foldable sequence remains one
of the greatest challenges in protein engineering". Additionally, aside from
this target design feature, the rest of the protein structure is often
irrelevant, and thus we would like a way to search for proteins based on a fuzzy
structural search.  One approach to this has been [searching over a latent
design
space](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1010271)
(e.g. from a VAE) to find proteins with the desired structural feature.

Here, I propose the approach of using an RL protein design agent along with
AlphaFold2 to assemble proteins conditioned on loose structural constraints. In
this process, the RL agent generates an amino acid sequence incrementally,
receiving feedback on how well the structure (from AlphaFold2) of the current
prototypical sequence meets the design criteria after each incremental
generation step.

One can think of this as either (1) a sequence generator as a model-free agent
in a simulated environment that is AlphaFold2 or (2) a model-based RL agent
where the policy is produced by the sequence generator and the model is
AlphaFold2, and the objective is to produce some output sequence that meets the
design criteria when it is actually synthesized in a lab. When thinking of this
as (2), one can see a sort of capability bootstrapping, where we can increase
intelligence related to proteins without having to collect any more measurements
from the real world. This is along the same line of thinking as Yoshua Bengio's
idea of [using a world model to develop a very large amortized inference
machine](https://yoshuabengio.org/2023/03/21/scaling-in-the-service-of-reasoning-model-based-ml/).

## Experiment 1

I first trained the agent to apply a minimal number of edits to a starting
sequence to maximize the AlphaFold pLDDT score, which quantifies how
well-defined the protein's structure is. I only looked at short sequences of 20
residues. I used a 2-layer transformer, and joinly embedded the initial and
starting sequence on a per-residue basis. After training for 16h on 8 4090s, the
model increases the aggregate pLDDT score by 25% within an edit distance of 4.

Interestingly, the model's strategy heavily favors adding Leucine (L) in
particular locations.

### Gallery

<div class="gallery-container">
  <div class="gallery">
    {% for image in site.static_files %}
      {% if image.path contains 'assets/images/qres' and image.extname == '.png' %}
        <div class="gallery-item">
          <img src="{{ image.path }}" alt="{{ image.name }}">
        </div>
      {% endif %}
    {% endfor %}
  </div>
</div>
